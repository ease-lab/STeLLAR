package main

import (
	"flag"
	"fmt"
	"io"
	"lambda-benchmarking/client/benchmarking"
	"lambda-benchmarking/client/visualization"
	"log"
	"math"
	"math/rand"
	"os"
	"path/filepath"
	"time"
)

//Note: those variables are pointers
var burstsFlag = flag.Int("bursts", 50, "Number of bursts which the latency profiler will trigger.")
var burstSizeFlag = flag.Int("burstSize", 1, "Number of requests to send in a burst.")

var payloadLengthBytesFlag = flag.Int("payloadLengthBytes", 5, "Length of the payload generated by the lambda function.")
var lambdaIncrementLimitFlag = flag.Int("lambdaIncrementLimit", 5e7, "Increment limit for the lambda function to busy spin on.")

var frequencySecondsFlag = flag.Int("frequencySeconds", -1, "Frequency at which the latency profiler operates.")
var randomizedFlag = flag.Bool("randomized", true, "If true, sample deltas from a scaled and shifted standard normal distribution.")

var visualizationFlag = flag.String("visualization", "CDF", "The type of visualization to create (per-burst histogram \"histogram\" or empirical CDF \"CDF\").")

var outputPathFlag = flag.String("outputPath", "latency-samples", "The path where latency samples should be written.")
//var gatewaysPathFlag = flag.String("gatewaysPath", "gateways.csv", "Configuration file with AWS Gateway API Endpoints to make requests to.")

// TODO: discontinue this and implement above flag
var gatewayEndpointFlag = flag.String("gatewayEndpoint", "", "The API Endpoint to make requests to.")

func main() {
	rand.Seed(time.Now().Unix())
	flag.Parse()

	outputDirectoryPath := filepath.Join(*outputPathFlag, time.Now().Format(time.RFC850))
	log.Printf("Creating working directory at %s", outputDirectoryPath)
	if err := os.Mkdir(outputDirectoryPath, os.ModePerm); err != nil {
		log.Fatal(err)
	}

	logFile, err := os.Create(filepath.Join(outputDirectoryPath, "run_logs.txt"))
	if err != nil {
		log.Fatal(err)
	}
	defer logFile.Close()

	stdoutFileMultiWriter := io.MultiWriter(os.Stdout, logFile)
	log.SetOutput(stdoutFileMultiWriter)

	// capped at 500 requests to avoid `race: limit on 8128 simultaneously alive goroutines is exceeded, dying`)
	*burstSizeFlag = int(math.Max(float64(*burstSizeFlag), 500))

	log.Printf("Started benchmarking HTTP client on %v.", time.Now().Format(time.RFC850))
	log.Printf("Parameters entered: %d requests in a burst, %dbytes payload length, %d busy spin counter, %ds profiler run frequency, output path was set to `%s`.",
		*burstSizeFlag, *payloadLengthBytesFlag, *lambdaIncrementLimitFlag, *frequencySecondsFlag, *outputPathFlag)

	csvFile, err := os.Create(filepath.Join(outputDirectoryPath, fmt.Sprintf(
		"%dbursts_%dreqs_freq%ds_payload%db_counter%d.csv",
		*burstsFlag,
		*burstSizeFlag,
		*frequencySecondsFlag,
		*payloadLengthBytesFlag,
		*lambdaIncrementLimitFlag)))
	if err != nil {
		log.Fatal(err)
	}
	defer csvFile.Close()

	burstDeltas := benchmarking.CreateBurstDeltas(*frequencySecondsFlag, *burstsFlag, *randomizedFlag)
	relativeBurstDeltas := benchmarking.MakeBurstDeltasRelative(burstDeltas)

	log.Println("Running profiler...")
	benchmarking.SafeWriterInstance.Initialize(csvFile)
	benchmarking.TriggerRelativeAsyncBurstGroups(*gatewayEndpointFlag, relativeBurstDeltas, *burstSizeFlag, *lambdaIncrementLimitFlag, *payloadLengthBytesFlag)

	log.Println("Flushing results to CSV file...")
	benchmarking.SafeWriterInstance.Writer.Flush()

	if *visualizationFlag == "" {
		log.Println("Skipping visualization...")
	} else {
		log.Printf("Creating %ss from CSV file `%s`", *visualizationFlag, csvFile.Name())
		visualization.GenerateVisualization(
			*visualizationFlag,
			*burstsFlag,
			burstDeltas,
			relativeBurstDeltas,
			csvFile,
			outputDirectoryPath,
		)
	}

	log.Println("Exiting...")
}
